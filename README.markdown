# autocache

Provides facilities for memozing function calls using pluggable cache backends.

Cache keys are generated by default by hashing the function's bytecode as well
as the arguments (including `*args`/`**kwargs`) passed to the cached function.

## Features

* Easy to use decorator implementation,
* Implicit versioning of cache keys based on introspection of generated
  bytecode -- no need to develop your own versioning or cache key naming schemes,
* Generation of cache keys from hashed argument values, safe to use with
  argument unpacking (`*args`, `**kwargs`) and complex hashable types,
* API compliant with [Django](https://docs.djangoproject.com/en/dev/topics/cache/)
  and [Flask](http://flask.pocoo.org/docs/patterns/caching/), and simple to
  create your own cache backends if your cache backend of choice is not already
  supported.

## Caveats

* Bytecode is not guaranteed to be the same between different interpreter
  versions or implementations (for example, Python 2.6 to 2.7, or CPython to
  PyPy.) In many cases the bytecode will be identical, but not always. Upgrading
  Python versions could result in a variation of the
  [thundering herd problem](http://en.wikipedia.org/wiki/Thundering_herd_problem).
* Refactoring of control structures may result in different bytecode generation,
  even if the underlying logic of the function is the same. (For instance,
  changing an `if`/`else` statement to a ternary statement.)
* All arguments values must implement the `__hash__` method, and this method
  must be [deterministic](http://en.wikipedia.org/wiki/Deterministic_algorithm)
  between interpreter restarts, etc. This makes it impossible to use lists or
  hashes as arguments to a cached function, unless you use a custom key
  generation function, or convert the values into a hashable type before calling
  the cache-wrapped function. (Future versions may offer greater support for
  unhashable types.)
* Some types (specifically, user defined class instances) are hashable, but not
  deterministic (their hash value evaluates to their `id()` -- in other words,
  their memory address) which can at worst result in cache misses, and at worst
  result in hash collisions and invalid results. Please take the time to
  understand the `__hash__` implementation of argument types that may be
  passed to your cached functions, and perhaps consider writing your own
  decorator that implements type checking to increase safety.

## Installation

To install from the git repository:

    pip install -e "git://github.com/tkaemming/autocache.git#egg=autocache"

## Usage

### autocache.cached(backend, \*\*kwargs)

**Keyword arguments:**

* **key:** use a user-defined cache key (not versioned) instead of hashing the
  function's bytecode
* **key_generator:** use a user-defined cache key generator instead of using
  `__hash__` on the args/kwargs passed to the callable
* **set_kwargs:** keyword arguments passed to the cache backend's `set` method,
  so you can pass timeouts, etc. when setting cached values

#### Example

For example, caching a function with Django's cache backend:

```python
from autocache import cached
from django.core.cache import cache

@cached(backend=cache)
def expensive_function(x):
    return x ** x

# This will be invoked, and the result will be stored in cache.
expensive_function(10)

# This will be served directly from cache.
expensive_function(10)

# This will be invoked, and the result will be stored in the cache
# as a new value (since `x=100` in this case)
expensive_function(100)
```

#### Using a user-defined base key

If you would like to use your own cache key (for reverse compatibility, or to
do manual versioning of keys), you can do so by passing the `key` keyword
argument to the decorator. (Argument values will still be hashed and added to
the key using the default argument hashing algorithm.)

```python
@cached(backend=cache, key='my-cache-key')
def foo(x):
    return x
```

#### Using a user-defined key function

TODO - Make sure arguments are hashable, refactor out hashed tuple generation, etc

#### Passing additional keyword arguments when setting cache values

To pass additional keyword arguments to the `set` function of the cache backend,
pass a dictionary to the `set_kwargs` argument of the decorator.

```python
@cached(backend=cache, set_kwargs={'timeout': 5 * 60})
def foo(x):
    return x
```

### Writing your own cache backend

To implement a cache backend, just create a class that supports the following
interface, and pass an instance of this object as the `backend` keyword argument
of the `cached` decorator:

```python
class CacheBackend(object):
    def get(self, key):
        """Get the value at `key`, returning `None` if there is no value."""
        pass

    def set(self, key, value):
        """Set the value of `key` to `value`."""
        pass
```

For a working example, please see the `SimpleCacheBackend` implementation in
`tests.py`.

## Contributing

### Quickstart

```bash
# optionally add "-p /usr/local/bin/pypy " argument if you have
# pypy installed and want to use it
virtualenv --no-site-packages autocache
cd autocache
echo "export PIP_RESPECT_VIRTUALENV=true" >> bin/activate
source bin/activate
git clone git://github.com/tkaemming/autocache.git repo
cd repo
```

### Running tests

To run the test suite, run `make test` in the repository directory.

### Style guidelines

Please generally follow [PEP8](http://www.python.org/dev/peps/pep-0008/) style
if you are planning on submitting patches.

Before submitting a patch, please make sure that it passes both pyflakes tests
and PEP8 checks by running `make check`.

## License

MIT Licensed, see `LICENSE` for the full text.

## Authors

* Ted Kaemming: <https://github.com/tkaemming>
* Mike Tigas: <https://github.com/mtigas>
